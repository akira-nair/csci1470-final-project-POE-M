{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 19:38:25.641441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>processed_title</th>\n",
       "      <th>ups</th>\n",
       "      <th>keywords</th>\n",
       "      <th>row_1</th>\n",
       "      <th>row_2</th>\n",
       "      <th>row_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1020ac</td>\n",
       "      <td>There's nothing inside / There is nothing outs...</td>\n",
       "      <td>5</td>\n",
       "      <td>[('inside', 0.5268), ('outside', 0.3751), ('se...</td>\n",
       "      <td>There's nothing inside</td>\n",
       "      <td>There is nothing outside me</td>\n",
       "      <td>I search on in hope.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>107cob</td>\n",
       "      <td>From whole we crumble / Forever lost to chaos ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[('chaos', 0.5962), ('crumble', 0.4749), ('for...</td>\n",
       "      <td>From whole we crumble</td>\n",
       "      <td>Forever lost to chaos</td>\n",
       "      <td>Never one again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109a51</td>\n",
       "      <td>Indistinctiveness / Immeasurability / Capitalism</td>\n",
       "      <td>3</td>\n",
       "      <td>[('indistinctiveness', 0.7664), ('immeasurabil...</td>\n",
       "      <td>Indistinctiveness</td>\n",
       "      <td>Immeasurability</td>\n",
       "      <td>Capitalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10eysi</td>\n",
       "      <td>Internet is down / Obligations go bye-bye / Of...</td>\n",
       "      <td>9</td>\n",
       "      <td>[('office', 0.5033), ('obligations', 0.4663), ...</td>\n",
       "      <td>Internet is down</td>\n",
       "      <td>Obligations go bye-bye</td>\n",
       "      <td>Office rejoices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10f79k</td>\n",
       "      <td>Cotton in my mouth / Needles in my blood and b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[('needles', 0.5314), ('cotton', 0.4806), ('bl...</td>\n",
       "      <td>Cotton in my mouth</td>\n",
       "      <td>Needles in my blood and bones</td>\n",
       "      <td>Hammers in my head.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id                                    processed_title  ups  \\\n",
       "0           0  1020ac  There's nothing inside / There is nothing outs...    5   \n",
       "1           1  107cob  From whole we crumble / Forever lost to chaos ...    1   \n",
       "2           2  109a51   Indistinctiveness / Immeasurability / Capitalism    3   \n",
       "3           3  10eysi  Internet is down / Obligations go bye-bye / Of...    9   \n",
       "4           4  10f79k  Cotton in my mouth / Needles in my blood and b...    1   \n",
       "\n",
       "                                            keywords                   row_1  \\\n",
       "0  [('inside', 0.5268), ('outside', 0.3751), ('se...  There's nothing inside   \n",
       "1  [('chaos', 0.5962), ('crumble', 0.4749), ('for...   From whole we crumble   \n",
       "2  [('indistinctiveness', 0.7664), ('immeasurabil...       Indistinctiveness   \n",
       "3  [('office', 0.5033), ('obligations', 0.4663), ...        Internet is down   \n",
       "4  [('needles', 0.5314), ('cotton', 0.4806), ('bl...      Cotton in my mouth   \n",
       "\n",
       "                           row_2                 row_3  \n",
       "0    There is nothing outside me  I search on in hope.  \n",
       "1          Forever lost to chaos       Never one again  \n",
       "2                Immeasurability            Capitalism  \n",
       "3         Obligations go bye-bye       Office rejoices  \n",
       "4  Needles in my blood and bones   Hammers in my head.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/haiku.csv')\n",
    "data = data.replace(\"/\", \" / \", regex=True)\n",
    "data = data.dropna()\n",
    "split_by_row = data[\"processed_title\"].str.split(\" / \", n = 3, expand = True)\n",
    "data[\"row_1\"] = split_by_row[0]\n",
    "data[\"row_2\"] = split_by_row[1]\n",
    "data[\"row_3\"] = split_by_row[2]\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row: str):\n",
    "    tokens = row.lower().split() # lower punctuations\n",
    "    tokens = [process_token(t) for t in tokens] # take off punctuations \n",
    "    return tokens # returns an array words in a row \n",
    "\n",
    "def process_token(token: str):\n",
    "    return re.sub(r'[^\\w\\s]', '', token.strip()) # gets rid of punctuations\n",
    "\n",
    "def vectorize(tokens):\n",
    "    vocab, index = {}, 1\n",
    "    vocab['<pad>'] = 0\n",
    "    for token in tokens:\n",
    "        token = token.strip()\n",
    "        if token not in vocab:\n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    return vocab # returns an dictionary (words to indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row1 = \" \".join(data[\"row_1\"].to_list())\n",
    "# row2 = \" \".join(data[\"row_2\"].to_list())\n",
    "# row3 = \" \".join(data[\"row_3\"].to_list())\n",
    "# # tokenize each row \n",
    "# tokens1 = tokenize(row1)\n",
    "# tokens2 = tokenize(row2)\n",
    "# tokens3 = tokenize(row3)\n",
    "# # vectorizing each row\n",
    "# vocab_map1 = vectorize(row1)\n",
    "# vocab_map2 = vectorize(row2)\n",
    "# vocab_map3 = vectorize(row3)\n",
    "\n",
    "# for the entire poem\n",
    "all_dictionary = \" \".join(data[\"processed_title\"].to_list())\n",
    "tokens = tokenize(all_dictionary)\n",
    "all_vocab_map = vectorize(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " 'theres': 1,\n",
       " 'nothing': 2,\n",
       " 'inside': 3,\n",
       " '': 4,\n",
       " 'there': 5,\n",
       " 'is': 6,\n",
       " 'outside': 7,\n",
       " 'me': 8,\n",
       " 'i': 9,\n",
       " 'search': 10,\n",
       " 'on': 11,\n",
       " 'in': 12,\n",
       " 'hope': 13,\n",
       " 'from': 14,\n",
       " 'whole': 15,\n",
       " 'we': 16,\n",
       " 'crumble': 17,\n",
       " 'forever': 18,\n",
       " 'lost': 19,\n",
       " 'to': 20,\n",
       " 'chaos': 21,\n",
       " 'never': 22,\n",
       " 'one': 23,\n",
       " 'again': 24,\n",
       " 'indistinctiveness': 25,\n",
       " 'immeasurability': 26,\n",
       " 'capitalism': 27,\n",
       " 'internet': 28,\n",
       " 'down': 29,\n",
       " 'obligations': 30,\n",
       " 'go': 31,\n",
       " 'byebye': 32,\n",
       " 'office': 33,\n",
       " 'rejoices': 34,\n",
       " 'cotton': 35,\n",
       " 'my': 36,\n",
       " 'mouth': 37,\n",
       " 'needles': 38,\n",
       " 'blood': 39,\n",
       " 'and': 40,\n",
       " 'bones': 41,\n",
       " 'hammers': 42,\n",
       " 'head': 43,\n",
       " 'mighty': 44,\n",
       " 'hummingbird': 45,\n",
       " 'drinks': 46,\n",
       " 'a': 47,\n",
       " 'grapefruits': 48,\n",
       " 'blossom': 49,\n",
       " 'blots': 50,\n",
       " 'out': 51,\n",
       " 'an': 52,\n",
       " 'airplane': 53,\n",
       " 'downvotes': 54,\n",
       " 'fall': 55,\n",
       " 'as': 56,\n",
       " 'sharp': 57,\n",
       " 'snowflakes': 58,\n",
       " 'of': 59,\n",
       " 'early': 60,\n",
       " 'winter': 61,\n",
       " 'execution': 62,\n",
       " 'seven': 63,\n",
       " 'ships': 64,\n",
       " 'tonight': 65,\n",
       " 'guess': 66,\n",
       " 'shouldve': 67,\n",
       " 'said': 68,\n",
       " 'goodbye': 69,\n",
       " 'saw': 70,\n",
       " 'eight': 71,\n",
       " 'this': 72,\n",
       " 'morning': 73,\n",
       " 'big': 74,\n",
       " 'words': 75,\n",
       " 'are': 76,\n",
       " 'so': 77,\n",
       " 'bad': 78,\n",
       " 'they': 79,\n",
       " 'can': 80,\n",
       " 'ruin': 81,\n",
       " 'haiku': 82,\n",
       " 'refrigerator': 83,\n",
       " 'at': 84,\n",
       " 'the': 85,\n",
       " 'end': 86,\n",
       " 'life': 87,\n",
       " 'kings': 88,\n",
       " 'queens': 89,\n",
       " 'pawns': 90,\n",
       " 'same': 91,\n",
       " 'box': 92,\n",
       " 'free': 93,\n",
       " 'mans': 94,\n",
       " 'short': 95,\n",
       " 'success': 96,\n",
       " 'measured': 97,\n",
       " 'money': 98,\n",
       " 'all': 99,\n",
       " 'work': 100,\n",
       " 'no': 101,\n",
       " 'play': 102,\n",
       " 'like': 103,\n",
       " 'lemmings': 104,\n",
       " 'off': 105,\n",
       " 'cliffs': 106,\n",
       " 'humans': 107,\n",
       " 'flock': 108,\n",
       " 'leader': 109,\n",
       " 'who': 110,\n",
       " 'just': 111,\n",
       " 'blind': 112,\n",
       " 'you': 113,\n",
       " 'left': 114,\n",
       " 'before': 115,\n",
       " 'woke': 116,\n",
       " 'beds': 117,\n",
       " 'empty': 118,\n",
       " 'toothbrush': 119,\n",
       " 'minty': 120,\n",
       " 'world': 121,\n",
       " 'keeps': 122,\n",
       " 'spinning': 123,\n",
       " 'nobody': 124,\n",
       " 'notices': 125,\n",
       " 'but': 126,\n",
       " 'what': 127,\n",
       " 'if': 128,\n",
       " 'it': 129,\n",
       " 'stopped': 130,\n",
       " 'live': 131,\n",
       " 'our': 132,\n",
       " 'lives': 133,\n",
       " 'make': 134,\n",
       " 'safely': 135,\n",
       " 'death': 136,\n",
       " 'why': 137,\n",
       " 'not': 138,\n",
       " 'take': 139,\n",
       " 'some': 140,\n",
       " 'risks': 141,\n",
       " 'endless': 142,\n",
       " 'beauty': 143,\n",
       " 'natures': 144,\n",
       " 'finest': 145,\n",
       " 'gift': 146,\n",
       " 'that': 147,\n",
       " 'girls': 148,\n",
       " 'shining': 149,\n",
       " 'grin': 150,\n",
       " 'has': 151,\n",
       " 'mantra': 152,\n",
       " 'am': 153,\n",
       " 'sad': 154,\n",
       " 'discover': 155,\n",
       " 'fun': 156,\n",
       " 'over': 157,\n",
       " 'zombies': 158,\n",
       " 'real': 159,\n",
       " 'will': 160,\n",
       " 'break': 161,\n",
       " 'your': 162,\n",
       " 'fucking': 163,\n",
       " 'foot': 164,\n",
       " 'gimps': 165,\n",
       " 'slow': 166,\n",
       " 'hell': 167,\n",
       " 'buildings': 168,\n",
       " 'remain': 169,\n",
       " 'monuments': 170,\n",
       " 'excess': 171,\n",
       " 'be': 172,\n",
       " 'gone': 173,\n",
       " 'last': 174,\n",
       " 'drop': 175,\n",
       " 'oil': 176,\n",
       " 'burnt': 177,\n",
       " 'by': 178,\n",
       " 'tank': 179,\n",
       " 'war': 180,\n",
       " 'autumn': 181,\n",
       " 'chill': 182,\n",
       " 'descends': 183,\n",
       " 'electric': 184,\n",
       " 'blanket': 185,\n",
       " 'returns': 186,\n",
       " 'snug': 187,\n",
       " 'cocoon': 188,\n",
       " 'sociopath': 189,\n",
       " 'pee': 190,\n",
       " 'trickle': 191,\n",
       " 'economics': 192,\n",
       " 'peer': 193,\n",
       " 'mirror': 194,\n",
       " 'fear': 195,\n",
       " 'face': 196,\n",
       " 'see': 197,\n",
       " 'broken': 198,\n",
       " 'yet': 199,\n",
       " 'beating': 200,\n",
       " 'stand': 201,\n",
       " 'wall': 202,\n",
       " 'looking': 203,\n",
       " 'up': 204,\n",
       " 'cracks': 205,\n",
       " 'for': 206,\n",
       " 'signs': 207,\n",
       " 'future': 208,\n",
       " 'love': 209,\n",
       " 'light': 210,\n",
       " 'darkened': 211,\n",
       " 'may': 212,\n",
       " 'rest': 213,\n",
       " 'peace': 214,\n",
       " 'telltale': 215,\n",
       " 'arrive': 216,\n",
       " 'temper': 217,\n",
       " 'sickness': 218,\n",
       " 'mornings': 219,\n",
       " 'hello': 220,\n",
       " 'mom': 221,\n",
       " 'dad': 222,\n",
       " 'tune': 223,\n",
       " 'xpost': 224,\n",
       " 'r': 225,\n",
       " 'video': 226,\n",
       " 'wouldnt': 227,\n",
       " 'mind': 228,\n",
       " 'while': 229,\n",
       " 'floating': 230,\n",
       " 'waves': 231,\n",
       " 'swallows': 232,\n",
       " 'saccharine': 233,\n",
       " 'pop': 234,\n",
       " 'spills': 235,\n",
       " 'car': 236,\n",
       " 'stereo': 237,\n",
       " 'its': 238,\n",
       " 'been': 239,\n",
       " 'long': 240,\n",
       " 'day': 241,\n",
       " 'mist': 242,\n",
       " 'fades': 243,\n",
       " 'time': 244,\n",
       " 'sun': 245,\n",
       " 'best': 246,\n",
       " 'gold': 247,\n",
       " 'her': 248,\n",
       " 'eyes': 249,\n",
       " 'kept': 250,\n",
       " 'westward': 251,\n",
       " 'city': 252,\n",
       " 'limits': 253,\n",
       " 'turn': 254,\n",
       " 'signal': 255,\n",
       " 'keep': 256,\n",
       " 'driving': 257,\n",
       " 'their': 258,\n",
       " 'kids': 259,\n",
       " 'could': 260,\n",
       " 'survive': 261,\n",
       " 'had': 262,\n",
       " 'stuff': 263,\n",
       " 'use': 264,\n",
       " 'wash': 265,\n",
       " 'suck': 266,\n",
       " 'haikus': 267,\n",
       " 'cant': 268,\n",
       " 'think': 269,\n",
       " 'anything': 270,\n",
       " 'nature': 271,\n",
       " 'roars': 272,\n",
       " 'die': 273,\n",
       " 'sheer': 274,\n",
       " 'terror': 275,\n",
       " 'those': 276,\n",
       " 'dont': 277,\n",
       " 'have': 278,\n",
       " 'ran': 279,\n",
       " 'better': 280,\n",
       " 'do': 281,\n",
       " 'or': 282,\n",
       " 'regret': 283,\n",
       " 'having': 284,\n",
       " 'done': 285,\n",
       " 'clouded': 286,\n",
       " 'tears': 287,\n",
       " 'seeing': 288,\n",
       " 'freshly': 289,\n",
       " 'dug': 290,\n",
       " 'grave': 291,\n",
       " 'beneath': 292,\n",
       " 'cover': 293,\n",
       " 'howl': 294,\n",
       " 'other': 295,\n",
       " 'poems': 296,\n",
       " 'coinsized': 297,\n",
       " 'spider': 298,\n",
       " 'birth': 299,\n",
       " 'moment': 300,\n",
       " 'well': 301,\n",
       " 'fails': 302,\n",
       " 'torches': 303,\n",
       " 'concrete': 304,\n",
       " 'caverns': 305,\n",
       " 'sky': 306,\n",
       " 'havent': 307,\n",
       " 'changed': 308,\n",
       " 'much': 309,\n",
       " 'upvotes': 310,\n",
       " 'increase': 311,\n",
       " 'wit': 312,\n",
       " 'comments': 313,\n",
       " 'decrease': 314,\n",
       " 'proportionately': 315,\n",
       " 'consolation': 316,\n",
       " 'prize': 317,\n",
       " 'goes': 318,\n",
       " 'ladies': 319,\n",
       " 'barbecue': 320,\n",
       " 'booth': 321,\n",
       " 'hooray': 322,\n",
       " 'vacancy': 323,\n",
       " 'heart': 324,\n",
       " 'hotel': 325,\n",
       " 'rented': 326,\n",
       " 'rooms': 327,\n",
       " 'pen': 328,\n",
       " 'lifted': 329,\n",
       " 'creations': 330,\n",
       " 'flow': 331,\n",
       " 'ceases': 332,\n",
       " 'ink': 333,\n",
       " 'meet': 334,\n",
       " 'bar': 335,\n",
       " 'bodies': 336,\n",
       " 'coalesce': 337,\n",
       " 'breakfast': 338,\n",
       " 'after': 339,\n",
       " 'dawn': 340,\n",
       " 'man': 341,\n",
       " 'paints': 342,\n",
       " 'streetlight': 343,\n",
       " 'lone': 344,\n",
       " 'star': 345,\n",
       " 'party': 346,\n",
       " 'bus': 347,\n",
       " 'austin': 348,\n",
       " 'exhausting': 349,\n",
       " 'put': 350,\n",
       " 'lime': 351,\n",
       " 'coconut': 352,\n",
       " 'fix': 353,\n",
       " 'belly': 354,\n",
       " 'ache': 355,\n",
       " 'clanks': 356,\n",
       " 'coiled': 357,\n",
       " 'wire': 358,\n",
       " 'dodge': 359,\n",
       " 'deep': 360,\n",
       " 'holes': 361,\n",
       " 'iced': 362,\n",
       " 'pavement': 363,\n",
       " 'very': 364,\n",
       " 'blown': 365,\n",
       " 'shock': 366,\n",
       " 'sweat': 367,\n",
       " 'everyday': 368,\n",
       " 'focus': 369,\n",
       " 'rises': 370,\n",
       " 'above': 371,\n",
       " 'conquer': 372,\n",
       " 'everything': 373,\n",
       " 'sitting': 374,\n",
       " 'desk': 375,\n",
       " 'butt': 376,\n",
       " 'starting': 377,\n",
       " 'sleep': 378,\n",
       " 'doesnt': 379,\n",
       " 'snore': 380,\n",
       " 'stupid': 381,\n",
       " 'flattened': 382,\n",
       " 'tire': 383,\n",
       " 'curse': 384,\n",
       " 'frigid': 385,\n",
       " 'night': 386,\n",
       " 'wait': 387,\n",
       " 'caa': 388,\n",
       " 'op': 389,\n",
       " 'fag': 390,\n",
       " 'bro': 391,\n",
       " 'he': 392,\n",
       " 'even': 393,\n",
       " 'lift': 394,\n",
       " 'jimmies': 395,\n",
       " 'rustled': 396,\n",
       " 'making': 397,\n",
       " 'deal': 398,\n",
       " 'with': 399,\n",
       " 'mother': 400,\n",
       " 'fucker': 401,\n",
       " 'socks': 402,\n",
       " 'smell': 403,\n",
       " 'bleach': 404,\n",
       " 'laundry': 405,\n",
       " 'week': 406,\n",
       " 'filthy': 407,\n",
       " 'redtube': 408,\n",
       " 'chilling': 409,\n",
       " 'homies': 410,\n",
       " 'need': 411,\n",
       " 'watermelon': 412,\n",
       " 'now': 413,\n",
       " 'used': 414,\n",
       " 'welfare': 415,\n",
       " 'ornithology': 416,\n",
       " 'wave': 417,\n",
       " 'behaviors': 418,\n",
       " 'glorious': 419,\n",
       " 'howd': 420,\n",
       " 'spell': 421,\n",
       " 'uh': 422,\n",
       " 'gee': 423,\n",
       " 'thanks': 424,\n",
       " 'help': 425,\n",
       " 'electricity': 426,\n",
       " 'flashing': 427,\n",
       " 'across': 428,\n",
       " 'illuminating': 429,\n",
       " 'dream': 430,\n",
       " 'god': 431,\n",
       " 'know': 432,\n",
       " 'ending': 433,\n",
       " 'none': 434,\n",
       " 'hear': 435,\n",
       " 'golden': 436,\n",
       " 'flashes': 437,\n",
       " 'emptiness': 438,\n",
       " 'darkness': 439,\n",
       " 'consumes': 440,\n",
       " 'shines': 441,\n",
       " 'afar': 442,\n",
       " 'pain': 443,\n",
       " 'freedom': 444,\n",
       " 'happiness': 445,\n",
       " 'dead': 446,\n",
       " 'flies': 447,\n",
       " 'pleasure': 448,\n",
       " 'sacrifice': 449,\n",
       " 'rubber': 450,\n",
       " 'ducky': 451,\n",
       " 'bitch': 452,\n",
       " 'first': 453,\n",
       " 'bachelors': 454,\n",
       " 'then': 455,\n",
       " 'mba': 456,\n",
       " 'jd': 457,\n",
       " 'wheres': 458,\n",
       " 'job': 459,\n",
       " 'celebrities': 460,\n",
       " 'say': 461,\n",
       " 'realize': 462,\n",
       " 'heavens': 463,\n",
       " 'blue': 464,\n",
       " 'vault': 465,\n",
       " 'crowded': 466,\n",
       " 'opulent': 467,\n",
       " 'clouds': 468,\n",
       " 'kites': 469,\n",
       " 'kami': 470,\n",
       " 'bridge': 471,\n",
       " 'vast': 472,\n",
       " 'crossing': 473,\n",
       " 'gaps': 474,\n",
       " 'joining': 475,\n",
       " 'friends': 476,\n",
       " 'worldly': 477,\n",
       " 'within': 478,\n",
       " 'yay': 479,\n",
       " 'new': 480,\n",
       " 'subreddit': 481,\n",
       " 'funny': 482,\n",
       " 'damn': 483,\n",
       " 'dies': 484,\n",
       " 'eighty': 485,\n",
       " 'dropped': 486,\n",
       " 'soap': 487,\n",
       " 'prison': 488,\n",
       " 'shower': 489,\n",
       " 'was': 490,\n",
       " 'brutally': 491,\n",
       " 'stabbed': 492,\n",
       " 'migrating': 493,\n",
       " 'birds': 494,\n",
       " 'waters': 495,\n",
       " 'green': 496,\n",
       " 'sloped': 497,\n",
       " 'shore': 498,\n",
       " 'water': 499,\n",
       " 'treatment': 500,\n",
       " 'plant': 501,\n",
       " 'wrote': 502,\n",
       " 'didnt': 503,\n",
       " 'enjoy': 504,\n",
       " 'threw': 505,\n",
       " 'spherical': 506,\n",
       " 'shape': 507,\n",
       " 'suns': 508,\n",
       " 'bright': 509,\n",
       " 'essence': 510,\n",
       " 'contained': 511,\n",
       " 'white': 512,\n",
       " 'orb': 513,\n",
       " 'im': 514,\n",
       " 'around': 515,\n",
       " 'here': 516,\n",
       " 'seem': 517,\n",
       " 'nice': 518,\n",
       " 'people': 519,\n",
       " 'hard': 520,\n",
       " 'claw': 521,\n",
       " 'locked': 522,\n",
       " 'beak': 523,\n",
       " 'crushed': 524,\n",
       " 'landslide': 525,\n",
       " 'fighting': 526,\n",
       " '575': 527,\n",
       " 'peterson': 528,\n",
       " 'through': 529,\n",
       " '12': 530,\n",
       " '21': 531,\n",
       " 'kindle': 532,\n",
       " 'edition': 533,\n",
       " 'please': 534,\n",
       " 'share': 535,\n",
       " 'thoughts': 536,\n",
       " 'should': 537,\n",
       " 'afraid': 538,\n",
       " 'going': 539,\n",
       " 'back': 540,\n",
       " 'regularly': 541,\n",
       " 'scheduled': 542,\n",
       " 'programming': 543,\n",
       " 'walked': 544,\n",
       " 'field': 545,\n",
       " 'went': 546,\n",
       " 'along': 547,\n",
       " 'oh': 548,\n",
       " 'how': 549,\n",
       " 'dreams': 550,\n",
       " 'haunt': 551,\n",
       " 'show': 552,\n",
       " 'false': 553,\n",
       " 'reality': 554,\n",
       " 'lived': 555,\n",
       " 'fake': 556,\n",
       " 'parting': 557,\n",
       " 'ways': 558,\n",
       " 'bittersweet': 559,\n",
       " 'still': 560,\n",
       " 'beats': 561,\n",
       " 'confusing': 562,\n",
       " 'felt': 563,\n",
       " 'warm': 564,\n",
       " 'summer': 565,\n",
       " 'breeze': 566,\n",
       " 'sparkling': 567,\n",
       " 'air': 568,\n",
       " 'soul': 569,\n",
       " 'captured': 570,\n",
       " 'flight': 571,\n",
       " 'cloud': 572,\n",
       " 'two': 573,\n",
       " 'companions': 574,\n",
       " 'artists': 575,\n",
       " 'warcraft': 576,\n",
       " 'trick': 577,\n",
       " 'frozen': 578,\n",
       " 'running': 579,\n",
       " 'bye': 580,\n",
       " 'neverending': 581,\n",
       " 'kite': 582,\n",
       " 'rescued': 583,\n",
       " 'him': 584,\n",
       " 'she': 585,\n",
       " 'needs': 586,\n",
       " 'rescuing': 587,\n",
       " 'perhaps': 588,\n",
       " 'window': 589,\n",
       " 'fly': 590,\n",
       " 'paper': 591,\n",
       " 'sure': 592,\n",
       " 'covetous': 593,\n",
       " 'hands': 594,\n",
       " 'unhinge': 595,\n",
       " 'topmost': 596,\n",
       " 'button': 597,\n",
       " 'blouse': 598,\n",
       " 'sing': 599,\n",
       " 'song': 600,\n",
       " 'uplifting': 601,\n",
       " 'worlds': 602,\n",
       " 'falls': 603,\n",
       " 'silent': 604,\n",
       " 'snow': 605,\n",
       " 'canvas': 606,\n",
       " 'black': 607,\n",
       " 'birdsong': 608,\n",
       " 'bursting': 609,\n",
       " 'forth': 610,\n",
       " 'hotboxed': 611,\n",
       " 'fiveseater': 612,\n",
       " 'bullshitting': 613,\n",
       " 'stranger': 614,\n",
       " 'infatuation': 615,\n",
       " 'look': 616,\n",
       " 'wonders': 617,\n",
       " 'grateful': 618,\n",
       " 'today': 619,\n",
       " 'sexy': 620,\n",
       " 'spunky': 621,\n",
       " 'girl': 622,\n",
       " 'tolerates': 623,\n",
       " 'silliness': 624,\n",
       " 'means': 625,\n",
       " '3': 626,\n",
       " 'unwinds': 627,\n",
       " 'wonder': 628,\n",
       " 'youre': 629,\n",
       " 'stars': 630,\n",
       " '4i': 631,\n",
       " 'lie': 632,\n",
       " 'speechless': 633,\n",
       " 'gaze': 634,\n",
       " 'fixed': 635,\n",
       " 'upon': 636,\n",
       " 'beckons': 637,\n",
       " '5': 638,\n",
       " 'open': 639,\n",
       " 'away': 640,\n",
       " 'let': 641,\n",
       " 'honey': 642,\n",
       " 'bucket': 643,\n",
       " 'sits': 644,\n",
       " 'awaiting': 645,\n",
       " 'excrement': 646,\n",
       " 'falling': 647,\n",
       " 'rain': 648,\n",
       " 'brings': 649,\n",
       " 'social': 650,\n",
       " 'shyness': 651,\n",
       " 'where': 652,\n",
       " 'orpheus': 653,\n",
       " 'runs': 654,\n",
       " 'sober': 655,\n",
       " 'overcast': 656,\n",
       " 'clear': 657,\n",
       " 'stuck': 658,\n",
       " 'behind': 659,\n",
       " 'glass': 660,\n",
       " 'practice': 661,\n",
       " 'more': 662,\n",
       " 'become': 663,\n",
       " 'awesome': 664,\n",
       " 'would': 665,\n",
       " 'escape': 666,\n",
       " 'weiner': 667,\n",
       " 'pants': 668,\n",
       " 'case': 669,\n",
       " 'fire': 670,\n",
       " 'sleeping': 671,\n",
       " 'drug': 672,\n",
       " 'bed': 673,\n",
       " 'being': 674,\n",
       " 'dealer': 675,\n",
       " 'alarm': 676,\n",
       " 'law': 677,\n",
       " 'cooked': 678,\n",
       " 'pizza': 679,\n",
       " 'cut': 680,\n",
       " 'bastard': 681,\n",
       " 'into': 682,\n",
       " 'squares': 683,\n",
       " 'ate': 684,\n",
       " 'corners': 685,\n",
       " 'asks': 686,\n",
       " 'says': 687,\n",
       " 'stay': 688,\n",
       " 'delete': 689,\n",
       " 'number': 690,\n",
       " 'wedding': 691,\n",
       " 'bells': 692,\n",
       " 'ring': 693,\n",
       " 'dove': 694,\n",
       " 'released': 695,\n",
       " 'cage': 696,\n",
       " 'wilted': 697,\n",
       " 'chirp': 698,\n",
       " 'sweetly': 699,\n",
       " 'trees': 700,\n",
       " 'wish': 701,\n",
       " 'learn': 702,\n",
       " 'state': 703,\n",
       " 'knuckles': 704,\n",
       " 'tell': 705,\n",
       " 'lot': 706,\n",
       " 'menace': 707,\n",
       " 'south': 708,\n",
       " 'central': 709,\n",
       " 'drinking': 710,\n",
       " 'juice': 711,\n",
       " 'hood': 712,\n",
       " 'started': 713,\n",
       " 'five': 714,\n",
       " 'swiftly': 715,\n",
       " 'came': 716,\n",
       " 'curvy': 717,\n",
       " 'windy': 718,\n",
       " 'road': 719,\n",
       " 'seat': 720,\n",
       " 'belt': 721,\n",
       " 'against': 722,\n",
       " 'neck': 723,\n",
       " 'entombed': 724,\n",
       " 'thick': 725,\n",
       " 'whines': 726,\n",
       " 'does': 727,\n",
       " 'move': 728,\n",
       " 'icy': 729,\n",
       " 'write': 730,\n",
       " 'myself': 731,\n",
       " 'ponder': 732,\n",
       " 'petulance': 733,\n",
       " 'laserbeams': 734,\n",
       " 'called': 735,\n",
       " 'scifaiku': 736,\n",
       " 'were': 737,\n",
       " 'amazing': 738,\n",
       " 'seventy': 739,\n",
       " 'years': 740,\n",
       " 'give': 741,\n",
       " 'loves': 742,\n",
       " 'most': 743,\n",
       " 'embrace': 744,\n",
       " 'fits': 745,\n",
       " 'ever': 746,\n",
       " 'changing': 747,\n",
       " 'quickly': 748,\n",
       " 'word': 749,\n",
       " 'flowing': 750,\n",
       " 'valley': 751,\n",
       " 'koolaid': 752,\n",
       " 'yes': 753,\n",
       " 'farming': 754,\n",
       " 'harder': 755,\n",
       " 'than': 756,\n",
       " 'thought': 757,\n",
       " 'nemesis': 758,\n",
       " 'panini': 759,\n",
       " 'floor': 760,\n",
       " 'dogs': 761,\n",
       " 'happy': 762,\n",
       " 'least': 763,\n",
       " 'days': 764,\n",
       " 'beach': 765,\n",
       " 'sea': 766,\n",
       " 'grass': 767,\n",
       " 'mermaid': 768,\n",
       " 'born': 769,\n",
       " 'when': 770,\n",
       " 'kissed': 771,\n",
       " 'died': 772,\n",
       " 'whilst': 773,\n",
       " 'loved': 774,\n",
       " 'meow': 775,\n",
       " 'bark': 776,\n",
       " 'lasts': 777,\n",
       " 'souvenirs': 778,\n",
       " 'sand': 779,\n",
       " 'spines': 780,\n",
       " 'books': 781,\n",
       " 'shattered': 782,\n",
       " 'self': 783,\n",
       " 'esteem': 784,\n",
       " 'did': 785,\n",
       " 'get': 786,\n",
       " 'attached': 787,\n",
       " 'wrong': 788,\n",
       " 'drift': 789,\n",
       " 'far': 790,\n",
       " 'wading': 791,\n",
       " 'drought': 792,\n",
       " 'galaxy': 793,\n",
       " 'beyond': 794,\n",
       " 'horizons': 795,\n",
       " 'edge': 796,\n",
       " 'always': 797,\n",
       " 'reach': 798,\n",
       " 'obscure': 799,\n",
       " 'entity': 800,\n",
       " 'indicates': 801,\n",
       " 'existence': 802,\n",
       " 'consuming': 803,\n",
       " 'way': 804,\n",
       " 'high': 805,\n",
       " 'feel': 806,\n",
       " 'precious': 807,\n",
       " 'dumbass': 808,\n",
       " 'manager': 809,\n",
       " 'fixes': 810,\n",
       " 'wasted': 811,\n",
       " 'joy': 812,\n",
       " 'spring': 813,\n",
       " 'cometh': 814,\n",
       " 'sunset': 815,\n",
       " 'minute': 816,\n",
       " 'blog': 817,\n",
       " 'written': 818,\n",
       " 'waiting': 819,\n",
       " 'traffic': 820,\n",
       " 'markers': 821,\n",
       " 'special': 822,\n",
       " 'thing': 823,\n",
       " 'moon': 824,\n",
       " 'hides': 825,\n",
       " 'dark': 826,\n",
       " 'slaves': 827,\n",
       " 'bored': 828,\n",
       " 'reddit': 829,\n",
       " 'offers': 830,\n",
       " 'solace': 831,\n",
       " 'kittens': 832,\n",
       " 'titties': 833,\n",
       " 'captivated': 834,\n",
       " 'smile': 835,\n",
       " 'calls': 836,\n",
       " 'facebook': 837,\n",
       " 'list': 838,\n",
       " 'purge': 839,\n",
       " 'similar': 840,\n",
       " 'murder': 841,\n",
       " 'digital': 842,\n",
       " 'hatchet': 843,\n",
       " 'petal': 844,\n",
       " 'departs': 845,\n",
       " 'dancing': 846,\n",
       " 'patches': 847,\n",
       " 'wind': 848,\n",
       " 'cuts': 849,\n",
       " 'crab': 850,\n",
       " 'tuna': 851,\n",
       " 'salmon': 852,\n",
       " 'sweet': 853,\n",
       " 'potato': 854,\n",
       " 'waffle': 855,\n",
       " 'fries': 856,\n",
       " 'pinot': 857,\n",
       " 'grigio': 858,\n",
       " 'blissful': 859,\n",
       " 'misery': 860,\n",
       " 'beer': 861,\n",
       " 'cigarettes': 862,\n",
       " 'alone': 863,\n",
       " 'many': 864,\n",
       " 'vengeance': 865,\n",
       " 'sandwich': 866,\n",
       " 'eating': 867,\n",
       " 'pet': 868,\n",
       " 'truth': 869,\n",
       " 'wanted': 870,\n",
       " 'side': 871,\n",
       " 'deus': 872,\n",
       " 'ex': 873,\n",
       " 'machina': 874,\n",
       " 'pronouncing': 875,\n",
       " 'right': 876,\n",
       " 'only': 877,\n",
       " 'miss': 878,\n",
       " 'friendship': 879,\n",
       " 'meant': 880,\n",
       " 'sail': 881,\n",
       " 'docks': 882,\n",
       " 'squeezing': 883,\n",
       " 'agony': 884,\n",
       " 'splashes': 885,\n",
       " 'red': 886,\n",
       " 'faced': 887,\n",
       " 'relief': 888,\n",
       " 'starpricked': 889,\n",
       " 'past': 890,\n",
       " 'snowsalted': 891,\n",
       " 'woods': 892,\n",
       " 'clanging': 893,\n",
       " 'cabins': 894,\n",
       " 'remains': 895,\n",
       " 'point': 896,\n",
       " 'without': 897,\n",
       " 'tried': 898,\n",
       " 'guys': 899,\n",
       " 'chomp': 900,\n",
       " 'chew': 901,\n",
       " 'swallow': 902,\n",
       " 'silence': 903,\n",
       " 'heard': 904,\n",
       " 'gulp': 905,\n",
       " 'dissapoint': 906,\n",
       " 'finally': 907,\n",
       " 'cats': 908,\n",
       " 'id': 909,\n",
       " 'knead': 910,\n",
       " 'doughy': 911,\n",
       " 'butterface': 912,\n",
       " 'multigrain': 913,\n",
       " 'loaf': 914,\n",
       " 'touched': 915,\n",
       " 'breathing': 916,\n",
       " 'religious': 917,\n",
       " 'park': 918,\n",
       " 'want': 919,\n",
       " 'handicap': 920,\n",
       " 'unrequited': 921,\n",
       " 'really': 922,\n",
       " 'call': 923,\n",
       " 'lust': 924,\n",
       " 'emotionlessness': 925,\n",
       " 'void': 926,\n",
       " 'caused': 927,\n",
       " 'losing': 928,\n",
       " 'reflecting': 929,\n",
       " 'despair': 930,\n",
       " 'doing': 931,\n",
       " 'shaving': 932,\n",
       " 'leave': 933,\n",
       " 'mass': 934,\n",
       " 'pubes': 935,\n",
       " 'nasty': 936,\n",
       " 'fertile': 937,\n",
       " 'ground': 938,\n",
       " 'nope': 939,\n",
       " 'chuck': 940,\n",
       " 'testa': 941,\n",
       " 'soy': 942,\n",
       " 'un': 943,\n",
       " 'perdedor': 944,\n",
       " 'loser': 945,\n",
       " 'baby': 946,\n",
       " 'kill': 947,\n",
       " 'ideas': 948,\n",
       " 'overwhelming': 949,\n",
       " 'page': 950,\n",
       " 'shapes': 951,\n",
       " 'laying': 952,\n",
       " 'tread': 953,\n",
       " 'racing': 954,\n",
       " 'scared': 955,\n",
       " 'loyal': 956,\n",
       " 'land': 957,\n",
       " 'nor': 958,\n",
       " 'government': 959,\n",
       " 'milk': 960,\n",
       " 'sip': 961,\n",
       " 'cup': 962,\n",
       " 'lies': 963,\n",
       " 'lactose': 964,\n",
       " 'betrays': 965,\n",
       " 'held': 966,\n",
       " 'bear': 967,\n",
       " 'each': 968,\n",
       " 'others': 969,\n",
       " 'sharing': 970,\n",
       " 'shame': 971,\n",
       " 'remember': 972,\n",
       " 'ghost': 973,\n",
       " 'childhood': 974,\n",
       " 'friend': 975,\n",
       " 'monday': 976,\n",
       " 'sneaky': 977,\n",
       " 'weeping': 978,\n",
       " 'angel': 979,\n",
       " 'eye': 980,\n",
       " 'ill': 981,\n",
       " 'pass': 982,\n",
       " 'comfort': 983,\n",
       " 'leaves': 984,\n",
       " 'things': 985,\n",
       " 'balanced': 986,\n",
       " 'stones': 987,\n",
       " 'small': 988,\n",
       " 'orbs': 989,\n",
       " 'flickering': 990,\n",
       " 'moving': 991,\n",
       " 'dying': 992,\n",
       " 'dust': 993,\n",
       " 'solidarity': 994,\n",
       " 'painful': 995,\n",
       " 'express': 996,\n",
       " 'ship': 997,\n",
       " 'overnight': 998,\n",
       " 'feeling': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vocab_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>processed_title</th>\n",
       "      <th>ups</th>\n",
       "      <th>keywords</th>\n",
       "      <th>row_1</th>\n",
       "      <th>row_2</th>\n",
       "      <th>row_3</th>\n",
       "      <th>vectorized</th>\n",
       "      <th>row_vector_1</th>\n",
       "      <th>row_vector_2</th>\n",
       "      <th>row_vector_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1020ac</td>\n",
       "      <td>There's nothing inside / There is nothing outs...</td>\n",
       "      <td>5</td>\n",
       "      <td>[('inside', 0.5268), ('outside', 0.3751), ('se...</td>\n",
       "      <td>There's nothing inside</td>\n",
       "      <td>There is nothing outside me</td>\n",
       "      <td>I search on in hope.</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 2, 7, 8, 4, 9, 10, 11, 12, 13]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[5, 6, 2, 7, 8]</td>\n",
       "      <td>[9, 10, 11, 12, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>107cob</td>\n",
       "      <td>From whole we crumble / Forever lost to chaos ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[('chaos', 0.5962), ('crumble', 0.4749), ('for...</td>\n",
       "      <td>From whole we crumble</td>\n",
       "      <td>Forever lost to chaos</td>\n",
       "      <td>Never one again</td>\n",
       "      <td>[14, 15, 16, 17, 4, 18, 19, 20, 21, 4, 22, 23,...</td>\n",
       "      <td>[14, 15, 16, 17]</td>\n",
       "      <td>[18, 19, 20, 21]</td>\n",
       "      <td>[22, 23, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109a51</td>\n",
       "      <td>Indistinctiveness / Immeasurability / Capitalism</td>\n",
       "      <td>3</td>\n",
       "      <td>[('indistinctiveness', 0.7664), ('immeasurabil...</td>\n",
       "      <td>Indistinctiveness</td>\n",
       "      <td>Immeasurability</td>\n",
       "      <td>Capitalism</td>\n",
       "      <td>[25, 4, 26, 4, 27]</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10eysi</td>\n",
       "      <td>Internet is down / Obligations go bye-bye / Of...</td>\n",
       "      <td>9</td>\n",
       "      <td>[('office', 0.5033), ('obligations', 0.4663), ...</td>\n",
       "      <td>Internet is down</td>\n",
       "      <td>Obligations go bye-bye</td>\n",
       "      <td>Office rejoices</td>\n",
       "      <td>[28, 6, 29, 4, 30, 31, 32, 4, 33, 34]</td>\n",
       "      <td>[28, 6, 29]</td>\n",
       "      <td>[30, 31, 32]</td>\n",
       "      <td>[33, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10f79k</td>\n",
       "      <td>Cotton in my mouth / Needles in my blood and b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[('needles', 0.5314), ('cotton', 0.4806), ('bl...</td>\n",
       "      <td>Cotton in my mouth</td>\n",
       "      <td>Needles in my blood and bones</td>\n",
       "      <td>Hammers in my head.</td>\n",
       "      <td>[35, 12, 36, 37, 4, 38, 12, 36, 39, 40, 41, 4,...</td>\n",
       "      <td>[35, 12, 36, 37]</td>\n",
       "      <td>[38, 12, 36, 39, 40, 41]</td>\n",
       "      <td>[42, 12, 36, 43]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id                                    processed_title  ups  \\\n",
       "0           0  1020ac  There's nothing inside / There is nothing outs...    5   \n",
       "1           1  107cob  From whole we crumble / Forever lost to chaos ...    1   \n",
       "2           2  109a51   Indistinctiveness / Immeasurability / Capitalism    3   \n",
       "3           3  10eysi  Internet is down / Obligations go bye-bye / Of...    9   \n",
       "4           4  10f79k  Cotton in my mouth / Needles in my blood and b...    1   \n",
       "\n",
       "                                            keywords                   row_1  \\\n",
       "0  [('inside', 0.5268), ('outside', 0.3751), ('se...  There's nothing inside   \n",
       "1  [('chaos', 0.5962), ('crumble', 0.4749), ('for...   From whole we crumble   \n",
       "2  [('indistinctiveness', 0.7664), ('immeasurabil...       Indistinctiveness   \n",
       "3  [('office', 0.5033), ('obligations', 0.4663), ...        Internet is down   \n",
       "4  [('needles', 0.5314), ('cotton', 0.4806), ('bl...      Cotton in my mouth   \n",
       "\n",
       "                           row_2                 row_3  \\\n",
       "0    There is nothing outside me  I search on in hope.   \n",
       "1          Forever lost to chaos       Never one again   \n",
       "2                Immeasurability            Capitalism   \n",
       "3         Obligations go bye-bye       Office rejoices   \n",
       "4  Needles in my blood and bones   Hammers in my head.   \n",
       "\n",
       "                                          vectorized      row_vector_1  \\\n",
       "0  [1, 2, 3, 4, 5, 6, 2, 7, 8, 4, 9, 10, 11, 12, 13]         [1, 2, 3]   \n",
       "1  [14, 15, 16, 17, 4, 18, 19, 20, 21, 4, 22, 23,...  [14, 15, 16, 17]   \n",
       "2                                 [25, 4, 26, 4, 27]              [25]   \n",
       "3              [28, 6, 29, 4, 30, 31, 32, 4, 33, 34]       [28, 6, 29]   \n",
       "4  [35, 12, 36, 37, 4, 38, 12, 36, 39, 40, 41, 4,...  [35, 12, 36, 37]   \n",
       "\n",
       "               row_vector_2         row_vector_3  \n",
       "0           [5, 6, 2, 7, 8]  [9, 10, 11, 12, 13]  \n",
       "1          [18, 19, 20, 21]         [22, 23, 24]  \n",
       "2                      [26]                 [27]  \n",
       "3              [30, 31, 32]             [33, 34]  \n",
       "4  [38, 12, 36, 39, 40, 41]     [42, 12, 36, 43]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"vectorized\"] = data[\"processed_title\"].apply(lambda x: [all_vocab_map[t] for t in tokenize(x)])\n",
    "data[\"row_vector_1\"] =  data[\"row_1\"].apply(lambda x: [all_vocab_map[t] for t in tokenize(x)])\n",
    "data[\"row_vector_2\"] = data[\"row_2\"].apply(lambda x: [all_vocab_map[t] for t in tokenize(x)])\n",
    "data[\"row_vector_3\"] = data[\"row_3\"].apply(lambda x: [all_vocab_map[t] for t in tokenize(x)])\n",
    "data = data[[a.count(4) <= 2 for a in data['vectorized']]]\n",
    "data = data[data['vectorized'].apply(lambda x: len(x) <= 19)]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectorized_list = data[\"vectorized\"].to_list()\n",
    "padded_data = pad_sequences(data_vectorized_list, padding='post')\n",
    "haikus = np.array(padded_data)\n",
    "\n",
    "row1_vectorized_list = data[\"row_vector_1\"].to_list()\n",
    "padded_data = pad_sequences(data_vectorized_list, padding='post')\n",
    "row1_haiku = np.array(padded_data)\n",
    "\n",
    "row2_vectorized_list = data[\"row_vector_2\"].to_list()\n",
    "padded_data = pad_sequences(data_vectorized_list, padding='post')\n",
    "row2_haiku = np.array(padded_data)\n",
    "\n",
    "row3_vectorized_list = data[\"row_vector_3\"].to_list()\n",
    "padded_data = pad_sequences(data_vectorized_list, padding='post')\n",
    "row3_haiku = np.array(padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_row1 = []\n",
    "# row 1\n",
    "for word1 in row1_haiku:\n",
    "  for i in range(len(word1) - window_size + 1):\n",
    "    input_words = word1[i: i+window_size - 1]\n",
    "    output_words = word1[i + window_size - 1]\n",
    "    training_row1.append((input_words, output_words))\n",
    "\n",
    "training_row2 = []\n",
    "# row 2\n",
    "for word2 in row1_haiku:\n",
    "  for i in range(len(word2) - window_size + 1):\n",
    "    input_words = word2[i: i+window_size - 1]\n",
    "    output_words = word2[i + window_size - 1]\n",
    "    training_row2.append((input_words, output_words))\n",
    "\n",
    "training_row3 = []\n",
    "# row 2\n",
    "for word3 in row1_haiku:\n",
    "  for i in range(len(word3) - window_size + 1):\n",
    "    input_words = word3[i: i+window_size - 1]\n",
    "    output_words = word3[i + window_size - 1]\n",
    "    training_row3.append((input_words, output_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, SimpleRNN, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 19:38:39.239939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(all_vocab_map)\n",
    "embedding_size = 128\n",
    "input_length = window_size - 1\n",
    "model1 = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=input_length),\n",
    "    GRU(32),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model2 = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=input_length),\n",
    "    GRU(32),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model3 = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=input_length),\n",
    "    GRU(32),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def masked_loss(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, 0), K.floatx())\n",
    "    loss = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    masked_loss = loss * mask\n",
    "    return K.sum(masked_loss) / K.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "optimizer2 = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "optimizer3 = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model1.compile(loss=masked_loss, optimizer=optimizer1, metrics=['accuracy'])\n",
    "model2.compile(loss=masked_loss, optimizer=optimizer2, metrics=['accuracy'])\n",
    "model3.compile(loss=masked_loss, optimizer=optimizer3, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([example[0] for example in training_row1[:15000]])\n",
    "y1 = np.array([example[1] for example in training_row1[:15000]])\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size= 0.1)\n",
    "\n",
    "x2 = np.array([example[0] for example in training_row2[:15000]])\n",
    "y2 = np.array([example[1] for example in training_row2[:15000]])\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size= 0.1)\n",
    "\n",
    "x3 = np.array([example[0] for example in training_row3[:15000]])\n",
    "y3 = np.array([example[1] for example in training_row3[:15000]])\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "106/106 [==============================] - 10s 65ms/step - loss: 838.5930 - accuracy: 0.2467 - val_loss: 691.4929 - val_accuracy: 0.2307\n",
      "Epoch 2/3\n",
      "106/106 [==============================] - 6s 57ms/step - loss: 625.5115 - accuracy: 0.2515 - val_loss: 692.5399 - val_accuracy: 0.2520\n",
      "Epoch 3/3\n",
      "106/106 [==============================] - 7s 62ms/step - loss: 604.8640 - accuracy: 0.2956 - val_loss: 701.3381 - val_accuracy: 0.2933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8af8e67550>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model1.fit(x_train1, y_train1, batch_size=128, epochs=3, validation_data=(x_test1, y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "106/106 [==============================] - 11s 72ms/step - loss: 849.7679 - accuracy: 0.2439 - val_loss: 668.2561 - val_accuracy: 0.2547\n",
      "Epoch 2/3\n",
      "106/106 [==============================] - 7s 63ms/step - loss: 628.4813 - accuracy: 0.2481 - val_loss: 671.9811 - val_accuracy: 0.2933\n",
      "Epoch 3/3\n",
      "106/106 [==============================] - 7s 65ms/step - loss: 607.5367 - accuracy: 0.2897 - val_loss: 683.5865 - val_accuracy: 0.3067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8af785c0a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model2.fit(x_train2, y_train2, batch_size=128, epochs=3, validation_data=(x_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "106/106 [==============================] - 12s 69ms/step - loss: 836.9170 - accuracy: 0.2453 - val_loss: 680.2072 - val_accuracy: 0.2433\n",
      "Epoch 2/3\n",
      "106/106 [==============================] - 7s 63ms/step - loss: 625.8229 - accuracy: 0.2644 - val_loss: 682.2524 - val_accuracy: 0.3060\n",
      "Epoch 3/3\n",
      "106/106 [==============================] - 6s 59ms/step - loss: 604.9351 - accuracy: 0.3023 - val_loss: 694.7485 - val_accuracy: 0.3087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ae78f07f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model3.fit(x_train3, y_train3, batch_size=128, epochs=3, validation_data=(x_test3, y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<pad>',\n",
       " 1: 'theres',\n",
       " 2: 'nothing',\n",
       " 3: 'inside',\n",
       " 4: '',\n",
       " 5: 'there',\n",
       " 6: 'is',\n",
       " 7: 'outside',\n",
       " 8: 'me',\n",
       " 9: 'i',\n",
       " 10: 'search',\n",
       " 11: 'on',\n",
       " 12: 'in',\n",
       " 13: 'hope',\n",
       " 14: 'from',\n",
       " 15: 'whole',\n",
       " 16: 'we',\n",
       " 17: 'crumble',\n",
       " 18: 'forever',\n",
       " 19: 'lost',\n",
       " 20: 'to',\n",
       " 21: 'chaos',\n",
       " 22: 'never',\n",
       " 23: 'one',\n",
       " 24: 'again',\n",
       " 25: 'indistinctiveness',\n",
       " 26: 'immeasurability',\n",
       " 27: 'capitalism',\n",
       " 28: 'internet',\n",
       " 29: 'down',\n",
       " 30: 'obligations',\n",
       " 31: 'go',\n",
       " 32: 'byebye',\n",
       " 33: 'office',\n",
       " 34: 'rejoices',\n",
       " 35: 'cotton',\n",
       " 36: 'my',\n",
       " 37: 'mouth',\n",
       " 38: 'needles',\n",
       " 39: 'blood',\n",
       " 40: 'and',\n",
       " 41: 'bones',\n",
       " 42: 'hammers',\n",
       " 43: 'head',\n",
       " 44: 'mighty',\n",
       " 45: 'hummingbird',\n",
       " 46: 'drinks',\n",
       " 47: 'a',\n",
       " 48: 'grapefruits',\n",
       " 49: 'blossom',\n",
       " 50: 'blots',\n",
       " 51: 'out',\n",
       " 52: 'an',\n",
       " 53: 'airplane',\n",
       " 54: 'downvotes',\n",
       " 55: 'fall',\n",
       " 56: 'as',\n",
       " 57: 'sharp',\n",
       " 58: 'snowflakes',\n",
       " 59: 'of',\n",
       " 60: 'early',\n",
       " 61: 'winter',\n",
       " 62: 'execution',\n",
       " 63: 'seven',\n",
       " 64: 'ships',\n",
       " 65: 'tonight',\n",
       " 66: 'guess',\n",
       " 67: 'shouldve',\n",
       " 68: 'said',\n",
       " 69: 'goodbye',\n",
       " 70: 'saw',\n",
       " 71: 'eight',\n",
       " 72: 'this',\n",
       " 73: 'morning',\n",
       " 74: 'big',\n",
       " 75: 'words',\n",
       " 76: 'are',\n",
       " 77: 'so',\n",
       " 78: 'bad',\n",
       " 79: 'they',\n",
       " 80: 'can',\n",
       " 81: 'ruin',\n",
       " 82: 'haiku',\n",
       " 83: 'refrigerator',\n",
       " 84: 'at',\n",
       " 85: 'the',\n",
       " 86: 'end',\n",
       " 87: 'life',\n",
       " 88: 'kings',\n",
       " 89: 'queens',\n",
       " 90: 'pawns',\n",
       " 91: 'same',\n",
       " 92: 'box',\n",
       " 93: 'free',\n",
       " 94: 'mans',\n",
       " 95: 'short',\n",
       " 96: 'success',\n",
       " 97: 'measured',\n",
       " 98: 'money',\n",
       " 99: 'all',\n",
       " 100: 'work',\n",
       " 101: 'no',\n",
       " 102: 'play',\n",
       " 103: 'like',\n",
       " 104: 'lemmings',\n",
       " 105: 'off',\n",
       " 106: 'cliffs',\n",
       " 107: 'humans',\n",
       " 108: 'flock',\n",
       " 109: 'leader',\n",
       " 110: 'who',\n",
       " 111: 'just',\n",
       " 112: 'blind',\n",
       " 113: 'you',\n",
       " 114: 'left',\n",
       " 115: 'before',\n",
       " 116: 'woke',\n",
       " 117: 'beds',\n",
       " 118: 'empty',\n",
       " 119: 'toothbrush',\n",
       " 120: 'minty',\n",
       " 121: 'world',\n",
       " 122: 'keeps',\n",
       " 123: 'spinning',\n",
       " 124: 'nobody',\n",
       " 125: 'notices',\n",
       " 126: 'but',\n",
       " 127: 'what',\n",
       " 128: 'if',\n",
       " 129: 'it',\n",
       " 130: 'stopped',\n",
       " 131: 'live',\n",
       " 132: 'our',\n",
       " 133: 'lives',\n",
       " 134: 'make',\n",
       " 135: 'safely',\n",
       " 136: 'death',\n",
       " 137: 'why',\n",
       " 138: 'not',\n",
       " 139: 'take',\n",
       " 140: 'some',\n",
       " 141: 'risks',\n",
       " 142: 'endless',\n",
       " 143: 'beauty',\n",
       " 144: 'natures',\n",
       " 145: 'finest',\n",
       " 146: 'gift',\n",
       " 147: 'that',\n",
       " 148: 'girls',\n",
       " 149: 'shining',\n",
       " 150: 'grin',\n",
       " 151: 'has',\n",
       " 152: 'mantra',\n",
       " 153: 'am',\n",
       " 154: 'sad',\n",
       " 155: 'discover',\n",
       " 156: 'fun',\n",
       " 157: 'over',\n",
       " 158: 'zombies',\n",
       " 159: 'real',\n",
       " 160: 'will',\n",
       " 161: 'break',\n",
       " 162: 'your',\n",
       " 163: 'fucking',\n",
       " 164: 'foot',\n",
       " 165: 'gimps',\n",
       " 166: 'slow',\n",
       " 167: 'hell',\n",
       " 168: 'buildings',\n",
       " 169: 'remain',\n",
       " 170: 'monuments',\n",
       " 171: 'excess',\n",
       " 172: 'be',\n",
       " 173: 'gone',\n",
       " 174: 'last',\n",
       " 175: 'drop',\n",
       " 176: 'oil',\n",
       " 177: 'burnt',\n",
       " 178: 'by',\n",
       " 179: 'tank',\n",
       " 180: 'war',\n",
       " 181: 'autumn',\n",
       " 182: 'chill',\n",
       " 183: 'descends',\n",
       " 184: 'electric',\n",
       " 185: 'blanket',\n",
       " 186: 'returns',\n",
       " 187: 'snug',\n",
       " 188: 'cocoon',\n",
       " 189: 'sociopath',\n",
       " 190: 'pee',\n",
       " 191: 'trickle',\n",
       " 192: 'economics',\n",
       " 193: 'peer',\n",
       " 194: 'mirror',\n",
       " 195: 'fear',\n",
       " 196: 'face',\n",
       " 197: 'see',\n",
       " 198: 'broken',\n",
       " 199: 'yet',\n",
       " 200: 'beating',\n",
       " 201: 'stand',\n",
       " 202: 'wall',\n",
       " 203: 'looking',\n",
       " 204: 'up',\n",
       " 205: 'cracks',\n",
       " 206: 'for',\n",
       " 207: 'signs',\n",
       " 208: 'future',\n",
       " 209: 'love',\n",
       " 210: 'light',\n",
       " 211: 'darkened',\n",
       " 212: 'may',\n",
       " 213: 'rest',\n",
       " 214: 'peace',\n",
       " 215: 'telltale',\n",
       " 216: 'arrive',\n",
       " 217: 'temper',\n",
       " 218: 'sickness',\n",
       " 219: 'mornings',\n",
       " 220: 'hello',\n",
       " 221: 'mom',\n",
       " 222: 'dad',\n",
       " 223: 'tune',\n",
       " 224: 'xpost',\n",
       " 225: 'r',\n",
       " 226: 'video',\n",
       " 227: 'wouldnt',\n",
       " 228: 'mind',\n",
       " 229: 'while',\n",
       " 230: 'floating',\n",
       " 231: 'waves',\n",
       " 232: 'swallows',\n",
       " 233: 'saccharine',\n",
       " 234: 'pop',\n",
       " 235: 'spills',\n",
       " 236: 'car',\n",
       " 237: 'stereo',\n",
       " 238: 'its',\n",
       " 239: 'been',\n",
       " 240: 'long',\n",
       " 241: 'day',\n",
       " 242: 'mist',\n",
       " 243: 'fades',\n",
       " 244: 'time',\n",
       " 245: 'sun',\n",
       " 246: 'best',\n",
       " 247: 'gold',\n",
       " 248: 'her',\n",
       " 249: 'eyes',\n",
       " 250: 'kept',\n",
       " 251: 'westward',\n",
       " 252: 'city',\n",
       " 253: 'limits',\n",
       " 254: 'turn',\n",
       " 255: 'signal',\n",
       " 256: 'keep',\n",
       " 257: 'driving',\n",
       " 258: 'their',\n",
       " 259: 'kids',\n",
       " 260: 'could',\n",
       " 261: 'survive',\n",
       " 262: 'had',\n",
       " 263: 'stuff',\n",
       " 264: 'use',\n",
       " 265: 'wash',\n",
       " 266: 'suck',\n",
       " 267: 'haikus',\n",
       " 268: 'cant',\n",
       " 269: 'think',\n",
       " 270: 'anything',\n",
       " 271: 'nature',\n",
       " 272: 'roars',\n",
       " 273: 'die',\n",
       " 274: 'sheer',\n",
       " 275: 'terror',\n",
       " 276: 'those',\n",
       " 277: 'dont',\n",
       " 278: 'have',\n",
       " 279: 'ran',\n",
       " 280: 'better',\n",
       " 281: 'do',\n",
       " 282: 'or',\n",
       " 283: 'regret',\n",
       " 284: 'having',\n",
       " 285: 'done',\n",
       " 286: 'clouded',\n",
       " 287: 'tears',\n",
       " 288: 'seeing',\n",
       " 289: 'freshly',\n",
       " 290: 'dug',\n",
       " 291: 'grave',\n",
       " 292: 'beneath',\n",
       " 293: 'cover',\n",
       " 294: 'howl',\n",
       " 295: 'other',\n",
       " 296: 'poems',\n",
       " 297: 'coinsized',\n",
       " 298: 'spider',\n",
       " 299: 'birth',\n",
       " 300: 'moment',\n",
       " 301: 'well',\n",
       " 302: 'fails',\n",
       " 303: 'torches',\n",
       " 304: 'concrete',\n",
       " 305: 'caverns',\n",
       " 306: 'sky',\n",
       " 307: 'havent',\n",
       " 308: 'changed',\n",
       " 309: 'much',\n",
       " 310: 'upvotes',\n",
       " 311: 'increase',\n",
       " 312: 'wit',\n",
       " 313: 'comments',\n",
       " 314: 'decrease',\n",
       " 315: 'proportionately',\n",
       " 316: 'consolation',\n",
       " 317: 'prize',\n",
       " 318: 'goes',\n",
       " 319: 'ladies',\n",
       " 320: 'barbecue',\n",
       " 321: 'booth',\n",
       " 322: 'hooray',\n",
       " 323: 'vacancy',\n",
       " 324: 'heart',\n",
       " 325: 'hotel',\n",
       " 326: 'rented',\n",
       " 327: 'rooms',\n",
       " 328: 'pen',\n",
       " 329: 'lifted',\n",
       " 330: 'creations',\n",
       " 331: 'flow',\n",
       " 332: 'ceases',\n",
       " 333: 'ink',\n",
       " 334: 'meet',\n",
       " 335: 'bar',\n",
       " 336: 'bodies',\n",
       " 337: 'coalesce',\n",
       " 338: 'breakfast',\n",
       " 339: 'after',\n",
       " 340: 'dawn',\n",
       " 341: 'man',\n",
       " 342: 'paints',\n",
       " 343: 'streetlight',\n",
       " 344: 'lone',\n",
       " 345: 'star',\n",
       " 346: 'party',\n",
       " 347: 'bus',\n",
       " 348: 'austin',\n",
       " 349: 'exhausting',\n",
       " 350: 'put',\n",
       " 351: 'lime',\n",
       " 352: 'coconut',\n",
       " 353: 'fix',\n",
       " 354: 'belly',\n",
       " 355: 'ache',\n",
       " 356: 'clanks',\n",
       " 357: 'coiled',\n",
       " 358: 'wire',\n",
       " 359: 'dodge',\n",
       " 360: 'deep',\n",
       " 361: 'holes',\n",
       " 362: 'iced',\n",
       " 363: 'pavement',\n",
       " 364: 'very',\n",
       " 365: 'blown',\n",
       " 366: 'shock',\n",
       " 367: 'sweat',\n",
       " 368: 'everyday',\n",
       " 369: 'focus',\n",
       " 370: 'rises',\n",
       " 371: 'above',\n",
       " 372: 'conquer',\n",
       " 373: 'everything',\n",
       " 374: 'sitting',\n",
       " 375: 'desk',\n",
       " 376: 'butt',\n",
       " 377: 'starting',\n",
       " 378: 'sleep',\n",
       " 379: 'doesnt',\n",
       " 380: 'snore',\n",
       " 381: 'stupid',\n",
       " 382: 'flattened',\n",
       " 383: 'tire',\n",
       " 384: 'curse',\n",
       " 385: 'frigid',\n",
       " 386: 'night',\n",
       " 387: 'wait',\n",
       " 388: 'caa',\n",
       " 389: 'op',\n",
       " 390: 'fag',\n",
       " 391: 'bro',\n",
       " 392: 'he',\n",
       " 393: 'even',\n",
       " 394: 'lift',\n",
       " 395: 'jimmies',\n",
       " 396: 'rustled',\n",
       " 397: 'making',\n",
       " 398: 'deal',\n",
       " 399: 'with',\n",
       " 400: 'mother',\n",
       " 401: 'fucker',\n",
       " 402: 'socks',\n",
       " 403: 'smell',\n",
       " 404: 'bleach',\n",
       " 405: 'laundry',\n",
       " 406: 'week',\n",
       " 407: 'filthy',\n",
       " 408: 'redtube',\n",
       " 409: 'chilling',\n",
       " 410: 'homies',\n",
       " 411: 'need',\n",
       " 412: 'watermelon',\n",
       " 413: 'now',\n",
       " 414: 'used',\n",
       " 415: 'welfare',\n",
       " 416: 'ornithology',\n",
       " 417: 'wave',\n",
       " 418: 'behaviors',\n",
       " 419: 'glorious',\n",
       " 420: 'howd',\n",
       " 421: 'spell',\n",
       " 422: 'uh',\n",
       " 423: 'gee',\n",
       " 424: 'thanks',\n",
       " 425: 'help',\n",
       " 426: 'electricity',\n",
       " 427: 'flashing',\n",
       " 428: 'across',\n",
       " 429: 'illuminating',\n",
       " 430: 'dream',\n",
       " 431: 'god',\n",
       " 432: 'know',\n",
       " 433: 'ending',\n",
       " 434: 'none',\n",
       " 435: 'hear',\n",
       " 436: 'golden',\n",
       " 437: 'flashes',\n",
       " 438: 'emptiness',\n",
       " 439: 'darkness',\n",
       " 440: 'consumes',\n",
       " 441: 'shines',\n",
       " 442: 'afar',\n",
       " 443: 'pain',\n",
       " 444: 'freedom',\n",
       " 445: 'happiness',\n",
       " 446: 'dead',\n",
       " 447: 'flies',\n",
       " 448: 'pleasure',\n",
       " 449: 'sacrifice',\n",
       " 450: 'rubber',\n",
       " 451: 'ducky',\n",
       " 452: 'bitch',\n",
       " 453: 'first',\n",
       " 454: 'bachelors',\n",
       " 455: 'then',\n",
       " 456: 'mba',\n",
       " 457: 'jd',\n",
       " 458: 'wheres',\n",
       " 459: 'job',\n",
       " 460: 'celebrities',\n",
       " 461: 'say',\n",
       " 462: 'realize',\n",
       " 463: 'heavens',\n",
       " 464: 'blue',\n",
       " 465: 'vault',\n",
       " 466: 'crowded',\n",
       " 467: 'opulent',\n",
       " 468: 'clouds',\n",
       " 469: 'kites',\n",
       " 470: 'kami',\n",
       " 471: 'bridge',\n",
       " 472: 'vast',\n",
       " 473: 'crossing',\n",
       " 474: 'gaps',\n",
       " 475: 'joining',\n",
       " 476: 'friends',\n",
       " 477: 'worldly',\n",
       " 478: 'within',\n",
       " 479: 'yay',\n",
       " 480: 'new',\n",
       " 481: 'subreddit',\n",
       " 482: 'funny',\n",
       " 483: 'damn',\n",
       " 484: 'dies',\n",
       " 485: 'eighty',\n",
       " 486: 'dropped',\n",
       " 487: 'soap',\n",
       " 488: 'prison',\n",
       " 489: 'shower',\n",
       " 490: 'was',\n",
       " 491: 'brutally',\n",
       " 492: 'stabbed',\n",
       " 493: 'migrating',\n",
       " 494: 'birds',\n",
       " 495: 'waters',\n",
       " 496: 'green',\n",
       " 497: 'sloped',\n",
       " 498: 'shore',\n",
       " 499: 'water',\n",
       " 500: 'treatment',\n",
       " 501: 'plant',\n",
       " 502: 'wrote',\n",
       " 503: 'didnt',\n",
       " 504: 'enjoy',\n",
       " 505: 'threw',\n",
       " 506: 'spherical',\n",
       " 507: 'shape',\n",
       " 508: 'suns',\n",
       " 509: 'bright',\n",
       " 510: 'essence',\n",
       " 511: 'contained',\n",
       " 512: 'white',\n",
       " 513: 'orb',\n",
       " 514: 'im',\n",
       " 515: 'around',\n",
       " 516: 'here',\n",
       " 517: 'seem',\n",
       " 518: 'nice',\n",
       " 519: 'people',\n",
       " 520: 'hard',\n",
       " 521: 'claw',\n",
       " 522: 'locked',\n",
       " 523: 'beak',\n",
       " 524: 'crushed',\n",
       " 525: 'landslide',\n",
       " 526: 'fighting',\n",
       " 527: '575',\n",
       " 528: 'peterson',\n",
       " 529: 'through',\n",
       " 530: '12',\n",
       " 531: '21',\n",
       " 532: 'kindle',\n",
       " 533: 'edition',\n",
       " 534: 'please',\n",
       " 535: 'share',\n",
       " 536: 'thoughts',\n",
       " 537: 'should',\n",
       " 538: 'afraid',\n",
       " 539: 'going',\n",
       " 540: 'back',\n",
       " 541: 'regularly',\n",
       " 542: 'scheduled',\n",
       " 543: 'programming',\n",
       " 544: 'walked',\n",
       " 545: 'field',\n",
       " 546: 'went',\n",
       " 547: 'along',\n",
       " 548: 'oh',\n",
       " 549: 'how',\n",
       " 550: 'dreams',\n",
       " 551: 'haunt',\n",
       " 552: 'show',\n",
       " 553: 'false',\n",
       " 554: 'reality',\n",
       " 555: 'lived',\n",
       " 556: 'fake',\n",
       " 557: 'parting',\n",
       " 558: 'ways',\n",
       " 559: 'bittersweet',\n",
       " 560: 'still',\n",
       " 561: 'beats',\n",
       " 562: 'confusing',\n",
       " 563: 'felt',\n",
       " 564: 'warm',\n",
       " 565: 'summer',\n",
       " 566: 'breeze',\n",
       " 567: 'sparkling',\n",
       " 568: 'air',\n",
       " 569: 'soul',\n",
       " 570: 'captured',\n",
       " 571: 'flight',\n",
       " 572: 'cloud',\n",
       " 573: 'two',\n",
       " 574: 'companions',\n",
       " 575: 'artists',\n",
       " 576: 'warcraft',\n",
       " 577: 'trick',\n",
       " 578: 'frozen',\n",
       " 579: 'running',\n",
       " 580: 'bye',\n",
       " 581: 'neverending',\n",
       " 582: 'kite',\n",
       " 583: 'rescued',\n",
       " 584: 'him',\n",
       " 585: 'she',\n",
       " 586: 'needs',\n",
       " 587: 'rescuing',\n",
       " 588: 'perhaps',\n",
       " 589: 'window',\n",
       " 590: 'fly',\n",
       " 591: 'paper',\n",
       " 592: 'sure',\n",
       " 593: 'covetous',\n",
       " 594: 'hands',\n",
       " 595: 'unhinge',\n",
       " 596: 'topmost',\n",
       " 597: 'button',\n",
       " 598: 'blouse',\n",
       " 599: 'sing',\n",
       " 600: 'song',\n",
       " 601: 'uplifting',\n",
       " 602: 'worlds',\n",
       " 603: 'falls',\n",
       " 604: 'silent',\n",
       " 605: 'snow',\n",
       " 606: 'canvas',\n",
       " 607: 'black',\n",
       " 608: 'birdsong',\n",
       " 609: 'bursting',\n",
       " 610: 'forth',\n",
       " 611: 'hotboxed',\n",
       " 612: 'fiveseater',\n",
       " 613: 'bullshitting',\n",
       " 614: 'stranger',\n",
       " 615: 'infatuation',\n",
       " 616: 'look',\n",
       " 617: 'wonders',\n",
       " 618: 'grateful',\n",
       " 619: 'today',\n",
       " 620: 'sexy',\n",
       " 621: 'spunky',\n",
       " 622: 'girl',\n",
       " 623: 'tolerates',\n",
       " 624: 'silliness',\n",
       " 625: 'means',\n",
       " 626: '3',\n",
       " 627: 'unwinds',\n",
       " 628: 'wonder',\n",
       " 629: 'youre',\n",
       " 630: 'stars',\n",
       " 631: '4i',\n",
       " 632: 'lie',\n",
       " 633: 'speechless',\n",
       " 634: 'gaze',\n",
       " 635: 'fixed',\n",
       " 636: 'upon',\n",
       " 637: 'beckons',\n",
       " 638: '5',\n",
       " 639: 'open',\n",
       " 640: 'away',\n",
       " 641: 'let',\n",
       " 642: 'honey',\n",
       " 643: 'bucket',\n",
       " 644: 'sits',\n",
       " 645: 'awaiting',\n",
       " 646: 'excrement',\n",
       " 647: 'falling',\n",
       " 648: 'rain',\n",
       " 649: 'brings',\n",
       " 650: 'social',\n",
       " 651: 'shyness',\n",
       " 652: 'where',\n",
       " 653: 'orpheus',\n",
       " 654: 'runs',\n",
       " 655: 'sober',\n",
       " 656: 'overcast',\n",
       " 657: 'clear',\n",
       " 658: 'stuck',\n",
       " 659: 'behind',\n",
       " 660: 'glass',\n",
       " 661: 'practice',\n",
       " 662: 'more',\n",
       " 663: 'become',\n",
       " 664: 'awesome',\n",
       " 665: 'would',\n",
       " 666: 'escape',\n",
       " 667: 'weiner',\n",
       " 668: 'pants',\n",
       " 669: 'case',\n",
       " 670: 'fire',\n",
       " 671: 'sleeping',\n",
       " 672: 'drug',\n",
       " 673: 'bed',\n",
       " 674: 'being',\n",
       " 675: 'dealer',\n",
       " 676: 'alarm',\n",
       " 677: 'law',\n",
       " 678: 'cooked',\n",
       " 679: 'pizza',\n",
       " 680: 'cut',\n",
       " 681: 'bastard',\n",
       " 682: 'into',\n",
       " 683: 'squares',\n",
       " 684: 'ate',\n",
       " 685: 'corners',\n",
       " 686: 'asks',\n",
       " 687: 'says',\n",
       " 688: 'stay',\n",
       " 689: 'delete',\n",
       " 690: 'number',\n",
       " 691: 'wedding',\n",
       " 692: 'bells',\n",
       " 693: 'ring',\n",
       " 694: 'dove',\n",
       " 695: 'released',\n",
       " 696: 'cage',\n",
       " 697: 'wilted',\n",
       " 698: 'chirp',\n",
       " 699: 'sweetly',\n",
       " 700: 'trees',\n",
       " 701: 'wish',\n",
       " 702: 'learn',\n",
       " 703: 'state',\n",
       " 704: 'knuckles',\n",
       " 705: 'tell',\n",
       " 706: 'lot',\n",
       " 707: 'menace',\n",
       " 708: 'south',\n",
       " 709: 'central',\n",
       " 710: 'drinking',\n",
       " 711: 'juice',\n",
       " 712: 'hood',\n",
       " 713: 'started',\n",
       " 714: 'five',\n",
       " 715: 'swiftly',\n",
       " 716: 'came',\n",
       " 717: 'curvy',\n",
       " 718: 'windy',\n",
       " 719: 'road',\n",
       " 720: 'seat',\n",
       " 721: 'belt',\n",
       " 722: 'against',\n",
       " 723: 'neck',\n",
       " 724: 'entombed',\n",
       " 725: 'thick',\n",
       " 726: 'whines',\n",
       " 727: 'does',\n",
       " 728: 'move',\n",
       " 729: 'icy',\n",
       " 730: 'write',\n",
       " 731: 'myself',\n",
       " 732: 'ponder',\n",
       " 733: 'petulance',\n",
       " 734: 'laserbeams',\n",
       " 735: 'called',\n",
       " 736: 'scifaiku',\n",
       " 737: 'were',\n",
       " 738: 'amazing',\n",
       " 739: 'seventy',\n",
       " 740: 'years',\n",
       " 741: 'give',\n",
       " 742: 'loves',\n",
       " 743: 'most',\n",
       " 744: 'embrace',\n",
       " 745: 'fits',\n",
       " 746: 'ever',\n",
       " 747: 'changing',\n",
       " 748: 'quickly',\n",
       " 749: 'word',\n",
       " 750: 'flowing',\n",
       " 751: 'valley',\n",
       " 752: 'koolaid',\n",
       " 753: 'yes',\n",
       " 754: 'farming',\n",
       " 755: 'harder',\n",
       " 756: 'than',\n",
       " 757: 'thought',\n",
       " 758: 'nemesis',\n",
       " 759: 'panini',\n",
       " 760: 'floor',\n",
       " 761: 'dogs',\n",
       " 762: 'happy',\n",
       " 763: 'least',\n",
       " 764: 'days',\n",
       " 765: 'beach',\n",
       " 766: 'sea',\n",
       " 767: 'grass',\n",
       " 768: 'mermaid',\n",
       " 769: 'born',\n",
       " 770: 'when',\n",
       " 771: 'kissed',\n",
       " 772: 'died',\n",
       " 773: 'whilst',\n",
       " 774: 'loved',\n",
       " 775: 'meow',\n",
       " 776: 'bark',\n",
       " 777: 'lasts',\n",
       " 778: 'souvenirs',\n",
       " 779: 'sand',\n",
       " 780: 'spines',\n",
       " 781: 'books',\n",
       " 782: 'shattered',\n",
       " 783: 'self',\n",
       " 784: 'esteem',\n",
       " 785: 'did',\n",
       " 786: 'get',\n",
       " 787: 'attached',\n",
       " 788: 'wrong',\n",
       " 789: 'drift',\n",
       " 790: 'far',\n",
       " 791: 'wading',\n",
       " 792: 'drought',\n",
       " 793: 'galaxy',\n",
       " 794: 'beyond',\n",
       " 795: 'horizons',\n",
       " 796: 'edge',\n",
       " 797: 'always',\n",
       " 798: 'reach',\n",
       " 799: 'obscure',\n",
       " 800: 'entity',\n",
       " 801: 'indicates',\n",
       " 802: 'existence',\n",
       " 803: 'consuming',\n",
       " 804: 'way',\n",
       " 805: 'high',\n",
       " 806: 'feel',\n",
       " 807: 'precious',\n",
       " 808: 'dumbass',\n",
       " 809: 'manager',\n",
       " 810: 'fixes',\n",
       " 811: 'wasted',\n",
       " 812: 'joy',\n",
       " 813: 'spring',\n",
       " 814: 'cometh',\n",
       " 815: 'sunset',\n",
       " 816: 'minute',\n",
       " 817: 'blog',\n",
       " 818: 'written',\n",
       " 819: 'waiting',\n",
       " 820: 'traffic',\n",
       " 821: 'markers',\n",
       " 822: 'special',\n",
       " 823: 'thing',\n",
       " 824: 'moon',\n",
       " 825: 'hides',\n",
       " 826: 'dark',\n",
       " 827: 'slaves',\n",
       " 828: 'bored',\n",
       " 829: 'reddit',\n",
       " 830: 'offers',\n",
       " 831: 'solace',\n",
       " 832: 'kittens',\n",
       " 833: 'titties',\n",
       " 834: 'captivated',\n",
       " 835: 'smile',\n",
       " 836: 'calls',\n",
       " 837: 'facebook',\n",
       " 838: 'list',\n",
       " 839: 'purge',\n",
       " 840: 'similar',\n",
       " 841: 'murder',\n",
       " 842: 'digital',\n",
       " 843: 'hatchet',\n",
       " 844: 'petal',\n",
       " 845: 'departs',\n",
       " 846: 'dancing',\n",
       " 847: 'patches',\n",
       " 848: 'wind',\n",
       " 849: 'cuts',\n",
       " 850: 'crab',\n",
       " 851: 'tuna',\n",
       " 852: 'salmon',\n",
       " 853: 'sweet',\n",
       " 854: 'potato',\n",
       " 855: 'waffle',\n",
       " 856: 'fries',\n",
       " 857: 'pinot',\n",
       " 858: 'grigio',\n",
       " 859: 'blissful',\n",
       " 860: 'misery',\n",
       " 861: 'beer',\n",
       " 862: 'cigarettes',\n",
       " 863: 'alone',\n",
       " 864: 'many',\n",
       " 865: 'vengeance',\n",
       " 866: 'sandwich',\n",
       " 867: 'eating',\n",
       " 868: 'pet',\n",
       " 869: 'truth',\n",
       " 870: 'wanted',\n",
       " 871: 'side',\n",
       " 872: 'deus',\n",
       " 873: 'ex',\n",
       " 874: 'machina',\n",
       " 875: 'pronouncing',\n",
       " 876: 'right',\n",
       " 877: 'only',\n",
       " 878: 'miss',\n",
       " 879: 'friendship',\n",
       " 880: 'meant',\n",
       " 881: 'sail',\n",
       " 882: 'docks',\n",
       " 883: 'squeezing',\n",
       " 884: 'agony',\n",
       " 885: 'splashes',\n",
       " 886: 'red',\n",
       " 887: 'faced',\n",
       " 888: 'relief',\n",
       " 889: 'starpricked',\n",
       " 890: 'past',\n",
       " 891: 'snowsalted',\n",
       " 892: 'woods',\n",
       " 893: 'clanging',\n",
       " 894: 'cabins',\n",
       " 895: 'remains',\n",
       " 896: 'point',\n",
       " 897: 'without',\n",
       " 898: 'tried',\n",
       " 899: 'guys',\n",
       " 900: 'chomp',\n",
       " 901: 'chew',\n",
       " 902: 'swallow',\n",
       " 903: 'silence',\n",
       " 904: 'heard',\n",
       " 905: 'gulp',\n",
       " 906: 'dissapoint',\n",
       " 907: 'finally',\n",
       " 908: 'cats',\n",
       " 909: 'id',\n",
       " 910: 'knead',\n",
       " 911: 'doughy',\n",
       " 912: 'butterface',\n",
       " 913: 'multigrain',\n",
       " 914: 'loaf',\n",
       " 915: 'touched',\n",
       " 916: 'breathing',\n",
       " 917: 'religious',\n",
       " 918: 'park',\n",
       " 919: 'want',\n",
       " 920: 'handicap',\n",
       " 921: 'unrequited',\n",
       " 922: 'really',\n",
       " 923: 'call',\n",
       " 924: 'lust',\n",
       " 925: 'emotionlessness',\n",
       " 926: 'void',\n",
       " 927: 'caused',\n",
       " 928: 'losing',\n",
       " 929: 'reflecting',\n",
       " 930: 'despair',\n",
       " 931: 'doing',\n",
       " 932: 'shaving',\n",
       " 933: 'leave',\n",
       " 934: 'mass',\n",
       " 935: 'pubes',\n",
       " 936: 'nasty',\n",
       " 937: 'fertile',\n",
       " 938: 'ground',\n",
       " 939: 'nope',\n",
       " 940: 'chuck',\n",
       " 941: 'testa',\n",
       " 942: 'soy',\n",
       " 943: 'un',\n",
       " 944: 'perdedor',\n",
       " 945: 'loser',\n",
       " 946: 'baby',\n",
       " 947: 'kill',\n",
       " 948: 'ideas',\n",
       " 949: 'overwhelming',\n",
       " 950: 'page',\n",
       " 951: 'shapes',\n",
       " 952: 'laying',\n",
       " 953: 'tread',\n",
       " 954: 'racing',\n",
       " 955: 'scared',\n",
       " 956: 'loyal',\n",
       " 957: 'land',\n",
       " 958: 'nor',\n",
       " 959: 'government',\n",
       " 960: 'milk',\n",
       " 961: 'sip',\n",
       " 962: 'cup',\n",
       " 963: 'lies',\n",
       " 964: 'lactose',\n",
       " 965: 'betrays',\n",
       " 966: 'held',\n",
       " 967: 'bear',\n",
       " 968: 'each',\n",
       " 969: 'others',\n",
       " 970: 'sharing',\n",
       " 971: 'shame',\n",
       " 972: 'remember',\n",
       " 973: 'ghost',\n",
       " 974: 'childhood',\n",
       " 975: 'friend',\n",
       " 976: 'monday',\n",
       " 977: 'sneaky',\n",
       " 978: 'weeping',\n",
       " 979: 'angel',\n",
       " 980: 'eye',\n",
       " 981: 'ill',\n",
       " 982: 'pass',\n",
       " 983: 'comfort',\n",
       " 984: 'leaves',\n",
       " 985: 'things',\n",
       " 986: 'balanced',\n",
       " 987: 'stones',\n",
       " 988: 'small',\n",
       " 989: 'orbs',\n",
       " 990: 'flickering',\n",
       " 991: 'moving',\n",
       " 992: 'dying',\n",
       " 993: 'dust',\n",
       " 994: 'solidarity',\n",
       " 995: 'painful',\n",
       " 996: 'express',\n",
       " 997: 'ship',\n",
       " 998: 'overnight',\n",
       " 999: 'feeling',\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_map_inv = dict([(value, key) for key, value in all_vocab_map.items()])\n",
    "vocab_map_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(input_words: list):\n",
    "    while len(input_words) < window_size - 1:\n",
    "        input_words.insert(0, \"<pad>\")\n",
    "    vectorized_input = [all_vocab_map[word] for word in input_words]\n",
    "    print(f\"User specified words {input_words} which were vectorized as {vectorized_input}\")\n",
    "    output_poem = input_words\n",
    "    \n",
    "    for i in range(5 - window_size - 1):\n",
    "        input = np.array(vectorized_input[i:i+window_size-1]).reshape((1, window_size-1))\n",
    "        prediction = np.array(model1.predict(input, verbose=0))\n",
    "        new_word_vector = (prediction[0].argsort()[::-1])[0]\n",
    "        vectorized_input.append(new_word_vector)\n",
    "        new_word = vocab_map_inv[new_word_vector]\n",
    "        print(new_word)\n",
    "        output_poem.append(new_word)\n",
    "        print(\"run\")\n",
    "    output_poem.append(\" / \")\n",
    "    for i in range(7 - window_size - 1):\n",
    "        input = np.array(vectorized_input[i:i+window_size-1]).reshape((1, window_size-1))\n",
    "        prediction = np.array(model2.predict(input, verbose=0))\n",
    "        new_word_vector = (prediction[0].argsort()[::-1])[0]\n",
    "        vectorized_input.append(new_word_vector)\n",
    "        new_word = vocab_map_inv[new_word_vector]\n",
    "        output_poem.append(new_word)\n",
    "    output_poem.append(\" / \")\n",
    "    for i in range(5 - window_size - 1):\n",
    "        input = np.array(vectorized_input[i:i+window_size-1]).reshape((1, window_size-1))\n",
    "        prediction = np.array(model3.predict(input, verbose=0))\n",
    "        new_word_vector = (prediction[0].argsort()[::-1])[0]\n",
    "        vectorized_input.append(new_word_vector)\n",
    "        new_word = vocab_map_inv[new_word_vector]\n",
    "        output_poem.append(new_word)\n",
    "\n",
    "    output = \" \".join(output_poem)\n",
    "    print(f\"OUTPUT POEM: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User specified words ['you', 'are', 'a', 'movie'] which were vectorized as [113, 76, 47, 4400]\n",
      "\n",
      "run\n",
      "\n",
      "run\n",
      "OUTPUT POEM: you are a movie    /       /   \n"
     ]
    }
   ],
   "source": [
    "generate_poem([\"you\",\"are\", \"a\", \"movie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8f96d5413b74ddc46885a35081fa54a9c7913f01fc2a6dfd5e34817588643e0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
